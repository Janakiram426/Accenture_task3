{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janakiram426/Accenture_task3/blob/master/Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Nt-N7Gjk6Rs1",
        "outputId": "890f0702-5390-4184-f64e-53757eb9b039"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Book1.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3c40f25dce0a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Read the Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Book1.xlsx'\u001b[0m  \u001b[0;31m# Replace with your Excel file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert to TSV and save it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Book1.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Excel file\n",
        "file_path = '/content/Book1.xlsx'  # Replace with your Excel file path\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Convert to TSV and save it\n",
        "tsv_file_path = 'output_file.tsv'  # Replace with your desired output file path\n",
        "df.to_csv(tsv_file_path, sep='\\t', index=False)\n",
        "\n",
        "print(f\"File successfully converted to {tsv_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3v4nqws7Wgc",
        "outputId": "6391f0e5-67d7-4a35-d67e-e2502e207f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Reply Author                                              Reply\n",
            "0      SUNNY RAI  Wtf totally hate spreading movie about punjab ...\n",
            "1     Aajad Khan                                         Nice movie\n",
            "2          abc d       fake n tatti action. pata nhi kab sudhrenge.\n",
            "3  Kamran Shafiq  i have never seen such a illogical movieÃ°ÂŸÂ¥ÂµÃ°ÂŸ...\n",
            "4  18+ Roastings  <a href=\"https://www.youtube.com/watch?v=_Sufd...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the TSV file into a pandas DataFrame, skipping bad lines\n",
        "file_path = '/content/output_file.tsv'\n",
        "\n",
        "df = pd.read_csv(file_path, sep='\\t', encoding='ISO-8859-1', on_bad_lines='skip')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "pCr5-n0NPdoH",
        "outputId": "19a89bf4-4159-4bdc-89b4-6abfe19d5a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-7a59aff802b2>:89: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop_duplicates(subset=['Reply'], inplace=True)\n",
            "<ipython-input-5-7a59aff802b2>:92: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(columns=['Word Count'], inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Reply Author                                              Reply\n",
              "0      SUNNY RAI  Wtf totally hate spreading movie about punjab ...\n",
              "2          abc d         fake n tatti action pata nhi kab sudhrenge\n",
              "3  Kamran Shafiq           i have never seen such a illogical movie\n",
              "8    Narain Dass  Lion of punjab all time fighting winner for Pu...\n",
              "9    Sudais info                     Tel me full movie release date"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9c2e8cc-bff5-41d5-a6db-ddd72f647e64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reply Author</th>\n",
              "      <th>Reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SUNNY RAI</td>\n",
              "      <td>Wtf totally hate spreading movie about punjab ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abc d</td>\n",
              "      <td>fake n tatti action pata nhi kab sudhrenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kamran Shafiq</td>\n",
              "      <td>i have never seen such a illogical movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Narain Dass</td>\n",
              "      <td>Lion of punjab all time fighting winner for Pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sudais info</td>\n",
              "      <td>Tel me full movie release date</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9c2e8cc-bff5-41d5-a6db-ddd72f647e64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9c2e8cc-bff5-41d5-a6db-ddd72f647e64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9c2e8cc-bff5-41d5-a6db-ddd72f647e64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e851e7cb-694c-46f7-9963-d1d049e363df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e851e7cb-694c-46f7-9963-d1d049e363df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e851e7cb-694c-46f7-9963-d1d049e363df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import re\n",
        "def replace_emojis(text):\n",
        "    # Replace some common emojis with words\n",
        "    text = text.replace('ğŸ‘ğŸ»', 'done')\n",
        "    text = text.replace('ğŸ™‚', 'smile')\n",
        "    text = text.replace('ğŸ˜', 'cool')\n",
        "    text = text.replace('ğŸ˜¢', 'sad')\n",
        "    text = text.replace('ğŸ˜‚', 'laugh')\n",
        "    text = text.replace('ğŸ™', 'thank you')\n",
        "    text = text.replace('â¤ï¸', 'love')\n",
        "    text = text.replace('ğŸ”¥', 'fire')\n",
        "    text = text.replace('ğŸ¤”', 'thinking')\n",
        "    text = text.replace('ğŸ’¯', 'hundred')\n",
        "    text = text.replace('ğŸ‘', 'clap')\n",
        "    text = text.replace('ğŸ˜Š', 'happy')\n",
        "    text = text.replace('ğŸ˜¡', 'angry')\n",
        "    text = text.replace('ğŸ˜', 'love')\n",
        "    text = text.replace('ğŸ˜œ', 'playful')\n",
        "    text = text.replace('ğŸ¤·â€â™‚ï¸', 'shrug')\n",
        "    text = text.replace('ğŸ¤¦â€â™‚ï¸', 'facepalm')\n",
        "    text = text.replace('ğŸ˜©', 'tired')\n",
        "    text = text.replace('ğŸ™„', 'eyeroll')\n",
        "    text = text.replace('ğŸ˜‡', 'blessed')\n",
        "    text = text.replace('ğŸ˜±', 'shocked')\n",
        "    text = text.replace('ğŸ˜´', 'sleepy')\n",
        "    text = text.replace('ğŸ’”', 'broken heart')\n",
        "    text = text.replace('ğŸŒŸ', 'star')\n",
        "    text = text.replace('ğŸ˜ ', 'mad')\n",
        "    text = text.replace('ğŸ¤¢', 'sick')\n",
        "    text = text.replace('ğŸ¤¡', 'clown')\n",
        "    text = text.replace('ğŸ‘€', 'eyes')\n",
        "    text = text.replace('ğŸ¤—', 'hug')\n",
        "    text = text.replace('ğŸ˜”', 'sad')\n",
        "    text = text.replace('ğŸ‰', 'celebrate')\n",
        "    text = text.replace('ğŸ’ª', 'strong')\n",
        "    text = text.replace('âœŒï¸', 'peace')\n",
        "    text = text.replace('ğŸ™Œ', 'praise')\n",
        "    text = text.replace('ğŸ˜¤', 'frustrated')\n",
        "    text = text.replace('ğŸ˜', 'smirk')\n",
        "    text = text.replace('ğŸ¤«', 'shh')\n",
        "    text = text.replace('ğŸ¥³', 'party')\n",
        "    text = text.replace('ğŸ¤¯', 'mindblown')\n",
        "    text = text.replace('ğŸ‘‹', 'wave')\n",
        "    text = text.replace('ğŸ’€', 'dead')\n",
        "    text = text.replace('ğŸ˜»', 'love')\n",
        "    text = text.replace('ğŸ˜¬', 'awkward')\n",
        "    text = text.replace('ğŸ¤¤', 'drool')\n",
        "    text = text.replace('ğŸ§', 'curious')\n",
        "    text = text.replace('ğŸ˜†', 'laugh')\n",
        "    text = text.replace('ğŸ˜‹', 'yum')\n",
        "    text = text.replace('ğŸ™ƒ', 'sarcastic')\n",
        "    text = text.replace('ğŸ˜…', 'nervous laugh')\n",
        "    text = text.replace('ğŸ˜', 'neutral')\n",
        "    text = text.replace('ğŸ’«', 'dizzy')\n",
        "    text = text.replace('ğŸ‘‘', 'king')\n",
        "    text = text.replace('âœ¨', 'sparkles')\n",
        "    text = text.replace('ğŸ¥º', 'pleading')\n",
        "    text = text.replace('ğŸ’–', 'love')\n",
        "    text = text.replace('ğŸ¤', 'handshake')\n",
        "    text = text.replace('ğŸ’¤', 'sleep')\n",
        "    return text\n",
        "\n",
        "# Update the cleaning function to include emoji replacement without using external library\n",
        "def clean_reply(reply):\n",
        "    # Check if the reply is a string\n",
        "    if isinstance(reply, str):\n",
        "        # 1. Remove HTML anchor tags\n",
        "        reply = re.sub('<a\\s+href=\"[^\"]+\">[^<]+</a>', '', reply)\n",
        "\n",
        "        # 2. Remove special characters (excluding spaces and alphanumeric characters)\n",
        "        reply = re.sub(f'[^A-Za-z0-9\\s]', '', reply)\n",
        "\n",
        "        # 3. Replace emojis with words using the custom function\n",
        "        reply = replace_emojis(reply)\n",
        "    else:\n",
        "        # Handle non-string values (e.g., convert to empty string)\n",
        "        reply = ''\n",
        "\n",
        "    return reply\n",
        "\n",
        "# Apply the updated cleaning function to the 'Reply' column\n",
        "df['Reply'] = df['Reply'].apply(clean_reply)\n",
        "\n",
        "# 4. Remove rows where the word count in the 'Reply' column is less than 3\n",
        "df['Word Count'] = df['Reply'].apply(lambda x: len(x.split()))\n",
        "df = df[df['Word Count'] >= 5]\n",
        "\n",
        "# 5. Remove duplicate comments in the 'Reply' column\n",
        "df.drop_duplicates(subset=['Reply'], inplace=True)\n",
        "\n",
        "# Drop the 'Word Count' column as it's no longer needed\n",
        "df.drop(columns=['Word Count'], inplace=True)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#new\n"
      ],
      "metadata": {
        "id": "ZNFCp19JOJun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Read the Excel file and convert to TSV\n",
        "input_file_path = '/content/Book1.xlsx'  # Replace with your Excel file path\n",
        "df = pd.read_excel(input_file_path)\n",
        "\n",
        "# Convert the DataFrame to TSV format and save it\n",
        "tsv_file_path = '/content/output_file.tsv'  # Desired output TSV file path\n",
        "df.to_csv(tsv_file_path, sep='\\t', index=False)\n",
        "print(f\"File successfully converted to {tsv_file_path}\")\n",
        "\n",
        "# Step 2: Read the TSV file into a pandas DataFrame, skipping bad lines\n",
        "df = pd.read_csv(tsv_file_path, sep='\\t', encoding='ISO-8859-1', on_bad_lines='skip')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"Initial Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Define a function to replace emojis with words\n",
        "def replace_emojis(text):\n",
        "    emoji_dict = {\n",
        "        'ğŸ‘ğŸ»': 'done', 'ğŸ™‚': 'smile', 'ğŸ˜': 'cool', 'ğŸ˜¢': 'sad', 'ğŸ˜‚': 'laugh',\n",
        "        'ğŸ™': 'thank you', 'â¤ï¸': 'love', 'ğŸ”¥': 'fire', 'ğŸ¤”': 'thinking',\n",
        "        'ğŸ’¯': 'hundred', 'ğŸ‘': 'clap', 'ğŸ˜Š': 'happy', 'ğŸ˜¡': 'angry',\n",
        "        'ğŸ˜': 'love', 'ğŸ˜œ': 'playful', 'ğŸ¤·â€â™‚ï¸': 'shrug', 'ğŸ¤¦â€â™‚ï¸': 'facepalm',\n",
        "        'ğŸ˜©': 'tired', 'ğŸ™„': 'eyeroll', 'ğŸ˜‡': 'blessed', 'ğŸ˜±': 'shocked',\n",
        "        'ğŸ˜´': 'sleepy', 'ğŸ’”': 'broken heart', 'ğŸŒŸ': 'star', 'ğŸ˜ ': 'mad',\n",
        "        'ğŸ¤¢': 'sick', 'ğŸ¤¡': 'clown', 'ğŸ‘€': 'eyes', 'ğŸ¤—': 'hug', 'ğŸ˜”': 'sad',\n",
        "        'ğŸ‰': 'celebrate', 'ğŸ’ª': 'strong', 'âœŒï¸': 'peace', 'ğŸ™Œ': 'praise',\n",
        "        'ğŸ˜¤': 'frustrated', 'ğŸ˜': 'smirk', 'ğŸ¤«': 'shh', 'ğŸ¥³': 'party',\n",
        "        'ğŸ¤¯': 'mindblown', 'ğŸ‘‹': 'wave', 'ğŸ’€': 'dead', 'ğŸ˜»': 'love',\n",
        "        'ğŸ˜¬': 'awkward', 'ğŸ¤¤': 'drool', 'ğŸ§': 'curious', 'ğŸ˜†': 'laugh',\n",
        "        'ğŸ˜‹': 'yum', 'ğŸ™ƒ': 'sarcastic', 'ğŸ˜…': 'nervous laugh', 'ğŸ˜': 'neutral',\n",
        "        'ğŸ’«': 'dizzy', 'ğŸ‘‘': 'king', 'âœ¨': 'sparkles', 'ğŸ¥º': 'pleading',\n",
        "        'ğŸ’–': 'love', 'ğŸ¤': 'handshake', 'ğŸ’¤': 'sleep'\n",
        "    }\n",
        "    for emoji, word in emoji_dict.items():\n",
        "        text = text.replace(emoji, word)\n",
        "    return text\n",
        "\n",
        "# Step 4: Define a function to clean replies\n",
        "def clean_reply(reply):\n",
        "    if isinstance(reply, str):\n",
        "        # Remove HTML anchor tags\n",
        "        reply = re.sub(r'<a\\s+href=\"[^\"]+\">[^<]+</a>', '', reply)\n",
        "\n",
        "        # Remove special characters (excluding spaces and alphanumeric characters)\n",
        "        reply = re.sub(r'[^A-Za-z0-9\\s]', '', reply)\n",
        "\n",
        "        # Replace emojis with words using the custom function\n",
        "        reply = replace_emojis(reply)\n",
        "    else:\n",
        "        # Handle non-string values\n",
        "        reply = ''\n",
        "    return reply\n",
        "\n",
        "# Step 5: Apply the cleaning function to the 'Reply' column\n",
        "if 'Reply' in df.columns:\n",
        "    df['Reply'] = df['Reply'].apply(clean_reply)\n",
        "else:\n",
        "    print(\"Error: 'Reply' column not found in the DataFrame\")\n",
        "\n",
        "# Step 6: Remove rows where the word count in 'Reply' is less than 5\n",
        "df['Word Count'] = df['Reply'].apply(lambda x: len(x.split()))\n",
        "df = df[df['Word Count'] >= 5]\n",
        "\n",
        "# Step 7: Remove duplicate comments in the 'Reply' column\n",
        "df.drop_duplicates(subset=['Reply'], inplace=True)\n",
        "\n",
        "# Step 8: Drop the 'Word Count' column as it's no longer needed\n",
        "df.drop(columns=['Word Count'], inplace=True)\n",
        "\n",
        "# Step 9: Display the cleaned DataFrame\n",
        "print(\"\\nCleaned Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 10: Save the cleaned DataFrame to a new TSV file\n",
        "output_file_path = '/content/cleaned_output_file.tsv'\n",
        "df.to_csv(output_file_path, sep='\\t', index=False)\n",
        "print(f\"\\nCleaned data saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8lvLRxN_90uo",
        "outputId": "5f328c92-639d-400f-ee3f-d42aec64402e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Book1.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3f0c61187238>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 1: Read the Excel file and convert to TSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Book1.xlsx'\u001b[0m  \u001b[0;31m# Replace with your Excel file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert the DataFrame to TSV format and save it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Book1.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91RQZVcrU8wo",
        "outputId": "3d734db6-0200-49af-d366-c6732aa2a222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296183 sha256=744524ec083844109024e90d4548583e16bfcb9e89d0f6b9a510b5aa3b7e0112\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYzpsVSWVniF",
        "outputId": "b586b2db-9177-4015-ee34-d651f49ccfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-24 14:15:02--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.44, 18.165.83.79, 18.165.83.91, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131266198 (125M) [application/octet-stream]\n",
            "Saving to: â€˜lid.176.binâ€™\n",
            "\n",
            "lid.176.bin         100%[===================>] 125.18M  48.8MB/s    in 2.6s    \n",
            "\n",
            "2024-10-24 14:15:05 (48.8 MB/s) - â€˜lid.176.binâ€™ saved [131266198/131266198]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_code_mixed(sentence, threshold=0.3):\n",
        "    \"\"\"\n",
        "    Detects if a sentence is code-mixed Telugu-English based on non-English words.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentence into words\n",
        "    tokens = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
        "\n",
        "    # Check how many words are not in the English dictionary\n",
        "    non_english_count = sum(1 for word in tokens if word not in english_words)\n",
        "\n",
        "    # Calculate the proportion of non-English words\n",
        "    if len(tokens) > 0:\n",
        "        non_english_ratio = non_english_count / len(tokens)\n",
        "    else:\n",
        "        non_english_ratio = 0\n",
        "\n",
        "    # Classify as code-mixed if the non-English ratio exceeds the threshold\n",
        "    return non_english_ratio >= threshold\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4MyiZj-1iMH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Step 1: Install and download English words corpus (run this once)\n",
        "nltk.download('words')\n",
        "\n",
        "# Get the set of English words from NLTK corpus\n",
        "english_words = set(nltk.corpus.words.words())\n",
        "\n",
        "# Step 2: Read the TSV file into a pandas DataFrame\n",
        "input_file_path = '/content/Dataset - filtered_code_mixed_output_file.tsv'  # Replace with your TSV file path\n",
        "df = pd.read_csv(input_file_path, sep='\\t', encoding='ISO-8859-1', on_bad_lines='skip')\n",
        "\n",
        "# Display the first few rows of the DataFrame and its columns\n",
        "print(\"Initial Data:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in the DataFrame:\", df.columns)\n",
        "\n",
        "# Step 3: Identify the comment column\n",
        "comment_column = df.columns[1]  # Assuming the second column contains the comments\n",
        "print(f\"\\nUsing '{comment_column}' column for processing comments.\")\n",
        "\n",
        "# Step 4: Define a function to replace emojis with words\n",
        "def replace_emojis(text):\n",
        "    emoji_dict = {\n",
        "        'ğŸ‘ğŸ»': 'done', 'ğŸ™‚': 'smile', 'ğŸ˜': 'cool', 'ğŸ˜¢': 'sad', 'ğŸ˜‚': 'laugh',\n",
        "        'ğŸ™': 'thank you', 'â¤ï¸': 'love', 'ğŸ”¥': 'fire', 'ğŸ¤”': 'thinking',\n",
        "        'ğŸ’¯': 'hundred', 'ğŸ‘': 'clap', 'ğŸ˜Š': 'happy', 'ğŸ˜¡': 'angry',\n",
        "        'ğŸ˜': 'love', 'ğŸ˜œ': 'playful', 'ğŸ¤·â€â™‚ï¸': 'shrug', 'ğŸ¤¦â€â™‚ï¸': 'facepalm',\n",
        "        'ğŸ˜©': 'tired', 'ğŸ™„': 'eyeroll', 'ğŸ˜‡': 'blessed', 'ğŸ˜±': 'shocked',\n",
        "        'ğŸ˜´': 'sleepy', 'ğŸ’”': 'broken heart', 'ğŸŒŸ': 'star', 'ğŸ˜ ': 'mad',\n",
        "        'ğŸ¤¢': 'sick', 'ğŸ¤¡': 'clown', 'ğŸ‘€': 'eyes', 'ğŸ¤—': 'hug', 'ğŸ˜”': 'sad',\n",
        "        'ğŸ‰': 'celebrate', 'ğŸ’ª': 'strong', 'âœŒï¸': 'peace', 'ğŸ™Œ': 'praise',\n",
        "        'ğŸ˜¤': 'frustrated', 'ğŸ˜': 'smirk', 'ğŸ¤«': 'shh', 'ğŸ¥³': 'party',\n",
        "        'ğŸ¤¯': 'mindblown', 'ğŸ‘‹': 'wave', 'ğŸ’€': 'dead', 'ğŸ˜»': 'love',\n",
        "        'ğŸ˜¬': 'awkward', 'ğŸ¤¤': 'drool', 'ğŸ§': 'curious', 'ğŸ˜†': 'laugh',\n",
        "        'ğŸ˜‹': 'yum', 'ğŸ™ƒ': 'sarcastic', 'ğŸ˜…': 'nervous laugh', 'ğŸ˜': 'neutral',\n",
        "        'ğŸ’«': 'dizzy', 'ğŸ‘‘': 'king', 'âœ¨': 'sparkles', 'ğŸ¥º': 'pleading',\n",
        "        'ğŸ’–': 'love', 'ğŸ¤': 'handshake', 'ğŸ’¤': 'sleep'\n",
        "    }\n",
        "    for emoji, word in emoji_dict.items():\n",
        "        text = text.replace(emoji, word)\n",
        "    return text\n",
        "\n",
        "# Step 5: Define a function to clean comments\n",
        "def clean_comment(comment):\n",
        "    if isinstance(comment, str):\n",
        "        # Remove HTML anchor tags\n",
        "        comment = re.sub(r'<a\\s+href=\"[^\"]+\">[^<]+</a>', '', comment)\n",
        "\n",
        "        # Remove special characters (excluding spaces and alphanumeric characters)\n",
        "        comment = re.sub(r'[^A-Za-z0-9\\s]', '', comment)\n",
        "\n",
        "        # Replace emojis with words using the custom function\n",
        "        comment = replace_emojis(comment)\n",
        "    else:\n",
        "        comment = ''\n",
        "    return comment\n",
        "\n",
        "# Step 6: Apply the cleaning function to the comment column\n",
        "df[comment_column] = df[comment_column].apply(clean_comment)\n",
        "\n",
        "# Step 7: Define a function to detect code-mixed comments\n",
        "def is_code_mixed(sentence, threshold=0.3):\n",
        "    tokens = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
        "    non_english_count = sum(1 for word in tokens if word not in english_words)\n",
        "    non_english_ratio = non_english_count / len(tokens) if len(tokens) > 0 else 0\n",
        "    return non_english_ratio >= threshold\n",
        "\n",
        "# Step 8: Filter code-mixed English-Telugu comments\n",
        "df['IsCodeMixed'] = df[comment_column].apply(is_code_mixed)\n",
        "\n",
        "# Keep only code-mixed comments\n",
        "df_code_mixed = df[df['IsCodeMixed']].copy()\n",
        "\n",
        "# Drop the 'IsCodeMixed' column\n",
        "df_code_mixed.drop(columns=['IsCodeMixed'], inplace=True)\n",
        "\n",
        "# Step 9: Save the cleaned and filtered DataFrame to a new TSV file\n",
        "output_file_path = '/content/filtered_code_mixed_output_file.tsv'\n",
        "df_code_mixed.to_csv(output_file_path, sep='\\t', index=False)\n",
        "print(f\"\\nCode-mixed English-Telugu data saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmkNmizCihmh",
        "outputId": "2ca8806a-7e6d-44e6-ef53-a3e0ca8633b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data:\n",
            "  KANDUKURI ANIL KUMAR          movie chusara frinds brEla undhi Chudocha\n",
            "0    youtube commentor  trailer lo kabaddi takkuva fights ekkuva unnay...\n",
            "1         hamsa balaji  Ap lo sports playerski inspiration iccheyyy mo...\n",
            "2                sam v  E movie chusaka director pirra mida kaadu chem...\n",
            "3                sam v  Sahasra Kanakagiri ya chusambrTelangana lo Kud...\n",
            "4              K Athik  E movie 3time chusen anna emundana denama abab...\n",
            "\n",
            "Columns in the DataFrame: Index(['KANDUKURI ANIL KUMAR', 'movie chusara frinds brEla undhi Chudocha'], dtype='object')\n",
            "\n",
            "Using 'movie chusara frinds brEla undhi Chudocha' column for processing comments.\n",
            "\n",
            "Code-mixed English-Telugu data saved to /content/filtered_code_mixed_output_file.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "y3HouRkb6laJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install and download English words corpus (run this once)\n",
        "nltk.download('words')\n",
        "\n",
        "# Get the set of English words from NLTK corpus\n",
        "english_words = set(nltk.corpus.words.words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAVuXXEX6nyY",
        "outputId": "3155edf4-1882-4d11-9438-b613371c3eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Read the TSV file into a pandas DataFrame\n",
        "input_file_path = '/content/Dataset - filtered_code_mixed_output_file.tsv'  # Replace with your TSV file path\n",
        "df = pd.read_csv(input_file_path, sep='\\t', encoding='ISO-8859-1', on_bad_lines='skip')\n"
      ],
      "metadata": {
        "id": "HfgJVxl86rPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame and its columns\n",
        "print(\"Initial Data:\")\n",
        "print(df.head())\n",
        "print(\"\\nColumns in the DataFrame:\", df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBUDQ3Zm6uPP",
        "outputId": "b3bf16dc-7abb-41a8-acee-1c6cca1d2ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data:\n",
            "  KANDUKURI ANIL KUMAR          movie chusara frinds brEla undhi Chudocha\n",
            "0    youtube commentor  trailer lo kabaddi takkuva fights ekkuva unnay...\n",
            "1         hamsa balaji  Ap lo sports playerski inspiration iccheyyy mo...\n",
            "2                sam v  E movie chusaka director pirra mida kaadu chem...\n",
            "3                sam v  Sahasra Kanakagiri ya chusambrTelangana lo Kud...\n",
            "4              K Athik  E movie 3time chusen anna emundana denama abab...\n",
            "\n",
            "Columns in the DataFrame: Index(['KANDUKURI ANIL KUMAR', 'movie chusara frinds brEla undhi Chudocha'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Identify the comment column\n",
        "comment_column = df.columns[1]  # Assuming the second column contains the comments\n",
        "print(f\"\\nUsing '{comment_column}' column for processing comments.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iENZHuH6xMB",
        "outputId": "ff13411e-a61b-4f90-fc30-33262dfe0e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using 'movie chusara frinds brEla undhi Chudocha' column for processing comments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define a function to replace emojis with words\n",
        "def replace_emojis(text):\n",
        "    emoji_dict = {\n",
        "        'ğŸ‘ğŸ»': 'done', 'ğŸ™‚': 'smile', 'ğŸ˜': 'cool', 'ğŸ˜¢': 'sad', 'ğŸ˜‚': 'laugh',\n",
        "        'ğŸ™': 'thank you', 'â¤ï¸': 'love', 'ğŸ”¥': 'fire', 'ğŸ¤”': 'thinking',\n",
        "        'ğŸ’¯': 'hundred', 'ğŸ‘': 'clap', 'ğŸ˜Š': 'happy', 'ğŸ˜¡': 'angry',\n",
        "        'ğŸ˜': 'love', 'ğŸ˜œ': 'playful', 'ğŸ¤·â€â™‚ï¸': 'shrug', 'ğŸ¤¦â€â™‚ï¸': 'facepalm',\n",
        "        'ğŸ˜©': 'tired', 'ğŸ™„': 'eyeroll', 'ğŸ˜‡': 'blessed', 'ğŸ˜±': 'shocked',\n",
        "        'ğŸ˜´': 'sleepy', 'ğŸ’”': 'broken heart', 'ğŸŒŸ': 'star', 'ğŸ˜ ': 'mad',\n",
        "        'ğŸ¤¢': 'sick', 'ğŸ¤¡': 'clown', 'ğŸ‘€': 'eyes', 'ğŸ¤—': 'hug', 'ğŸ˜”': 'sad',\n",
        "        'ğŸ‰': 'celebrate', 'ğŸ’ª': 'strong', 'âœŒï¸': 'peace', 'ğŸ™Œ': 'praise',\n",
        "        'ğŸ˜¤': 'frustrated', 'ğŸ˜': 'smirk', 'ğŸ¤«': 'shh', 'ğŸ¥³': 'party',\n",
        "        'ğŸ¤¯': 'mindblown', 'ğŸ‘‹': 'wave', 'ğŸ’€': 'dead', 'ğŸ˜»': 'love',\n",
        "        'ğŸ˜¬': 'awkward', 'ğŸ¤¤': 'drool', 'ğŸ§': 'curious', 'ğŸ˜†': 'laugh',\n",
        "        'ğŸ˜‹': 'yum', 'ğŸ™ƒ': 'sarcastic', 'ğŸ˜…': 'nervous laugh', 'ğŸ˜': 'neutral',\n",
        "        'ğŸ’«': 'dizzy', 'ğŸ‘‘': 'king', 'âœ¨': 'sparkles', 'ğŸ¥º': 'pleading',\n",
        "        'ğŸ’–': 'love', 'ğŸ¤': 'handshake', 'ğŸ’¤': 'sleep'\n",
        "    }\n",
        "    for emoji, word in emoji_dict.items():\n",
        "        text = text.replace(emoji, word)\n",
        "    return text"
      ],
      "metadata": {
        "id": "nysG82se7BlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define a function to clean comments\n",
        "def clean_comment(comment):\n",
        "    if isinstance(comment, str):\n",
        "        # Remove HTML anchor tags\n",
        "        comment = re.sub(r'<a\\s+href=\"[^\"]+\">[^<]+</a>', '', comment)\n",
        "\n",
        "        # Remove special characters (excluding spaces and alphanumeric characters)\n",
        "        comment = re.sub(r'[^A-Za-z0-9\\s]', '', comment)\n",
        "\n",
        "        # Replace emojis with words using the custom function\n",
        "        comment = replace_emojis(comment)\n",
        "    else:\n",
        "        comment = ''\n",
        "    return comment"
      ],
      "metadata": {
        "id": "48eApUPj7Frs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Define additional filtering functions\n",
        "def contains_unwanted_words_or_numbers(comment):\n",
        "    \"\"\"Check if the comment contains specific unwanted words or numbers.\"\"\"\n",
        "    if not isinstance(comment, str):\n",
        "        return False\n",
        "    # Unwanted words\n",
        "    unwanted_words = ['jai', 'all the best', 'br']\n",
        "    # Check for unwanted words\n",
        "    if any(word in comment.lower() for word in unwanted_words):\n",
        "        return True\n",
        "    # Check for numbers\n",
        "    if re.search(r'\\d', comment):  # Highlighted logic to detect numbers\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "c0f1mkqR7IuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def has_repeated_words(comment):\n",
        "  Check if the comment contains more than 3 repeated words.\n",
        "    words = comment.lower().split()\n",
        "    word_counts = pd.Series(words).value_counts()\n",
        "    return any(word_counts[word] > 3 for word in word_counts)\"\"\"\"\"\n"
      ],
      "metadata": {
        "id": "jcA_3cZ87NL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Apply the cleaning function to the comment column\n",
        "df[comment_column] = df[comment_column].map(clean_comment)\n"
      ],
      "metadata": {
        "id": "a-zXkqkR7PfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaned Comments:\")\n",
        "print(df[comment_column].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o3tnpu-7SBv",
        "outputId": "029324f6-1f3b-47eb-992b-6273d01d1eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned Comments:\n",
            "0    trailer lo kabaddi takkuva fights ekkuva unnay...\n",
            "1    Ap lo sports playerski inspiration iccheyyy mo...\n",
            "2    E movie chusaka director pirra mida kaadu chem...\n",
            "3    Sahasra Kanakagiri ya chusambrTelangana lo Kud...\n",
            "4    E movie 3time chusen anna emundana denama abab...\n",
            "Name: movie chusara frinds brEla undhi Chudocha, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Step 8: Remove comments containing unwanted words\n",
        "df_filtered = df[~df[comment_column].map(contains_unwanted_words_or_numbers)]\n"
      ],
      "metadata": {
        "id": "MZgyCSjv911B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index to prevent potential index mismatches\n",
        "df_filtered.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "hS8yAD5b97Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug: Display comments after removing unwanted words\n",
        "print(\"\\nComments after removing unwanted words:\")\n",
        "print(df_filtered[comment_column].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeWcY0OU99gN",
        "outputId": "89b80b29-24c3-4415-c8e3-37a6f0a8d32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comments after removing unwanted words:\n",
            "0    Ap lo sports playerski inspiration iccheyyy mo...\n",
            "1         Background score musi super manisharma gaaru\n",
            "2        Cenima chusi matladandi ra swamy endi ra sodi\n",
            "3    Telangana nu thakkuva chudadam baledhu nandhi ...\n",
            "4    Gopichand garu mee movie machi hit avvalani ko...\n",
            "Name: movie chusara frinds brEla undhi Chudocha, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Define a function to detect code-mixed comments\n",
        "def is_code_mixed(sentence, threshold=0.3):\n",
        "    tokens = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
        "    non_english_count = sum(1 for word in tokens if word not in english_words)\n",
        "    non_english_ratio = non_english_count / len(tokens) if len(tokens) > 0 else 0\n",
        "    return non_english_ratio >= threshold"
      ],
      "metadata": {
        "id": "7eUFFYOH-AV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Filter code-mixed English-Telugu comments\n",
        "code_mixed_mask = df_filtered[comment_column].map(is_code_mixed)\n",
        "df_code_mixed = df_filtered[code_mixed_mask].copy()"
      ],
      "metadata": {
        "id": "Ah4pNSTl-C5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug: Display the final filtered DataFrame\n",
        "print(\"\\nFinal Code-Mixed Comments:\")\n",
        "print(df_code_mixed[comment_column].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddGbzPw1-FOc",
        "outputId": "3041a239-25aa-4ae0-fdaa-e0ca06d1b486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Code-Mixed Comments:\n",
            "0    Ap lo sports playerski inspiration iccheyyy mo...\n",
            "1         Background score musi super manisharma gaaru\n",
            "2        Cenima chusi matladandi ra swamy endi ra sodi\n",
            "3    Telangana nu thakkuva chudadam baledhu nandhi ...\n",
            "4    Gopichand garu mee movie machi hit avvalani ko...\n",
            "Name: movie chusara frinds brEla undhi Chudocha, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Save the cleaned and filtered DataFrame to a new TSV file\n",
        "output_file_path = '/content/filtered_code_mixed_output_file.tsv'\n",
        "df_code_mixed.to_csv(output_file_path, sep='\\t', index=False)\n",
        "print(f\"\\nCode-mixed English-Telugu data saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plziFiF--IC_",
        "outputId": "11fa4654-2117-4e99-a88a-8599fc35a829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Code-mixed English-Telugu data saved to /content/filtered_code_mixed_output_file.tsv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}